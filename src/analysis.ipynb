{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Import the packages and functions\n",
    "from tools.functions import *\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions, parameters and directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definitions, parameters and directory paths\n",
    "# Define the base path for your images\n",
    "base_path       = '../img'\n",
    "\n",
    "# Define the path to your dataset within the base path and using gray images\n",
    "dataset_path    = f'{base_path}/dataset/gray/'\n",
    "\n",
    "# List of ratios to be used for splitting the dataset into training and testing sets\n",
    "train_ratio     = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "# Threshold for normalizing the image data\n",
    "thresh_normalization = 0.500\n",
    "\n",
    "# List of thresholds to be considered 'good' in evaluation\n",
    "thresh_good     = [0.00, 0.10, 0.15]\n",
    "\n",
    "# Range of iterations to be performed during model training\n",
    "iterations      = range(1, 6)\n",
    "\n",
    "# Define different classification types for the model to learn. Each type is associated with a list of categories.\n",
    "classification_types = {'n_grains': ['50', '60', '70', '80', '90', '100'], \n",
    "                        'defect_stratified': ['0%', '10%', '15%', '20%', '25%', '30%'], \n",
    "                        'defect_thresholded': ['With defects', 'Healthy']}\n",
    "\n",
    "# Define labels for the x and y axes in plotting\n",
    "x_label = 'Predicted'\n",
    "y_label = 'True'\n",
    "\n",
    "## ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all image filenames in the directory specified in dataset_path\n",
    "image_filenames = read_all_images_filenames(dataset_path)\n",
    "\n",
    "# Initialize an empty DataFrame for storing training data\n",
    "df_train                    = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame for storing testing data\n",
    "df_test                     = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame for storing model's training data\n",
    "df_train_model              = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame for storing classification results\n",
    "classification_results_df   = pd.DataFrame()\n",
    "\n",
    "# Initialize a nested dictionary for storing classification metrics results. \n",
    "# The structure is organized first by training ratio, then by threshold, and finally by classification type\n",
    "classification_metrics_results = {\n",
    "    ratio: {\n",
    "        thresh: {\n",
    "            classification_type: {} for classification_type in classification_types\n",
    "        } for thresh in thresh_good\n",
    "    } for ratio in train_ratio\n",
    "}\n",
    "\n",
    "# Initialize a nested dictionary for storing confusion matrices. \n",
    "# The structure is similar to that of classification_metrics_results\n",
    "confusion_matrices = {\n",
    "    ratio: {\n",
    "        thresh: {\n",
    "            classification_type: {} for classification_type in classification_types\n",
    "        } for thresh in thresh_good\n",
    "    } for ratio in train_ratio\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates the model and performs the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the procedure for all specified training/testing percentages, thresholds to consider good grains, and the number of iterations for each set\n",
    "for ratio in train_ratio:           \n",
    "    for thresh in thresh_good:\n",
    "        for iteration in iterations:\n",
    "\n",
    "            df_train                    = pd.DataFrame()\n",
    "            df_test                     = pd.DataFrame()\n",
    "            df_train_model              = pd.DataFrame()\n",
    "\n",
    "            # Divide the dataset into train and test sets with the specified ratio\n",
    "            train_filenames, test_filenames = divide_dataset(image_filenames, ratio)\n",
    "\n",
    "            # Create dataframes for the train and test sets using the filenames and images in the specified directory\n",
    "            df_train = create_dataframes(train_filenames, dataset_path)\n",
    "            df_test = create_dataframes(test_filenames, dataset_path)\n",
    "\n",
    "            # Normalize the 'ratio_80to255_to_1to80' feature in the train and test datasets. The normalization threshold is specified\n",
    "            df_train, df_test = normalize_dataset(df_train, df_test, 'ratio_80to255_to_1to80', thresh_normalization)\n",
    "\n",
    "            # Summarize the train dataframe by grouping it by grain_quantity and defect_percentage and calculating summary statistics to generate the model\n",
    "            df_train_model = summarize_train_data(df_train)\n",
    "\n",
    "            # Call the function to calculate the average number of pixels per grain for the training dataset\n",
    "            avg_pixels_1a255_per_grain = calculate_avg_pixels_per_grain(df_train)\n",
    "\n",
    "            # Calculate number of grains\n",
    "            df_test['calculated_grain_quantity'] = df_test['npixels_1to255'].apply(calculate_number_of_grains, grain_avg = avg_pixels_1a255_per_grain)\n",
    "\n",
    "            # Estimate number of grains (in discrete values predefined)\n",
    "            df_test['estimated_grain_quantity'] = df_test['calculated_grain_quantity'].apply(estimate_number_of_grains)\n",
    "\n",
    "            # Calculate the error between the actual and estimated values for the quantity of grains\n",
    "            df_test['error_grain'] = df_test['estimated_grain_quantity'] - df_test['grain_quantity']\n",
    "\n",
    "            # Estimate the percentage of defects in the test dataset based on the number of grains and ratio\n",
    "            df_test['estimated_defect_percentage'] = df_test.apply(lambda row: estimate_defect_percentage(row['grain_quantity'], \n",
    "                                                                                                           row['normalized_ratio_80to255_to_1to80'], df_train_model), axis=1)\n",
    "\n",
    "            # Calculate the error in the estimated defect percentage\n",
    "            df_test['error_defects'] = df_test['estimated_defect_percentage'] - df_test['defect_percentage']\n",
    "\n",
    "            # Select only the columns of interest to create a summarized dataframe with the classification results\n",
    "            classification_results_df = df_test[['grain_quantity', 'defect_percentage', 'estimated_grain_quantity', 'estimated_defect_percentage', 'error_grain']].copy()\n",
    "\n",
    "            # Check the quality (healthy or defective) according to the parameterized threshold\n",
    "            classification_results_df['quality'] = (classification_results_df['defect_percentage'].apply(check_quality, thresh)).astype(int)\n",
    "            classification_results_df['estimated_quality'] = (classification_results_df['estimated_defect_percentage'].apply(check_quality, thresh)).astype(int)\n",
    "            \n",
    "            # Iterate over each classification type and get the classification results\n",
    "            for classification_type in classification_types:\n",
    "\n",
    "                cm, cr = generate_confusion_matrix_and_classification_metrics(classification_results_df, classification_types[classification_type], classification_type)\n",
    "                \n",
    "                # Update the confusion matrix and classification metrics dictionaries\n",
    "                confusion_matrices[ratio][thresh][classification_type].update({iteration: cm})\n",
    "                classification_metrics_results[ratio][thresh][classification_type].update({iteration: cr})\n",
    "\n",
    "# Apply a cross-validation by taking the average of the results obtained in each iteration\n",
    "classification_metrics_results, confusion_matrices = cross_validation(train_ratio, thresh_good, classification_types, \n",
    "                                                                      iterations, classification_metrics_results, confusion_matrices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_all_confusion_matrices_images(train_ratio, thresh_good, classification_types, iterations, confusion_matrices, base_path, [x_label, y_label])\n",
    "\n",
    "with open(\"../resources/classification_metrics_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(classification_metrics_results, f)\n",
    "\n",
    "with open(\"../resources/confusion_matrices.pickle\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)\n",
    "\n",
    "df_test.to_pickle('../resources/df_test.pkl')\n",
    "df_train.to_pickle('../resources/df_train.pkl')\n",
    "df_train_model.to_pickle('../resources/df_train_model.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrizes de confusão (média) para quantidade de grãos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrices[train_ratio[0]][thresh_good[1]]['n_grains']['mean']\n",
    "# display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_075_ngrains.pdf', [x_label, y_label])\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[1]][thresh_good[1]]['n_grains']['mean']\n",
    "# # display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_080_ngrains.pdf', [x_label, y_label])\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[2]][thresh_good[1]]['n_grains']['mean']\n",
    "# # display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_085_ngrains.pdf', [x_label, y_label])\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[3]][thresh_good[1]]['n_grains']['mean']\n",
    "# # display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_090_ngrains.pdf', [x_label, y_label])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[0]][thresh_good[0]]['defect_stratified']['mean']\n",
    "# display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['defect_stratified'], r'img\\confusion_matrix\\defect_stratified\\resumidas\\cm_075_defect_stratified.pdf', [x_label, y_label])\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[1]][thresh_good[0]]['defect_stratified']['mean']\n",
    "# # display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['defect_stratified'], r'img\\confusion_matrix\\defect_stratified\\resumidas\\cm_080_defect_stratified.pdf', [x_label, y_label])\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[2]][thresh_good[0]]['defect_stratified']['mean']\n",
    "# # display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['defect_stratified'], r'img\\confusion_matrix\\defect_stratified\\resumidas\\cm_085_defect_stratified.pdf', [x_label, y_label])\n",
    "\n",
    "# cm = confusion_matrices[train_ratio[3]][thresh_good[0]]['defect_stratified']['mean']\n",
    "# # display(cm)\n",
    "# export_confusion_matrix_as_image(cm, classification_types['defect_stratified'], r'img\\confusion_matrix\\defect_stratified\\resumidas\\cm_090_defect_stratified.pdf', [x_label, y_label])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrices[train_ratio[0]][thresh_good[2]]['defect_thresholded']['mean']\n",
    "display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['defect_thresholded'], r'img\\confusion_matrix\\defect_thresholded\\resumidas\\cm_075_defect_thresholded_15.pdf', [x_label, y_label])\n",
    "\n",
    "cm = confusion_matrices[train_ratio[1]][thresh_good[2]]['defect_thresholded']['mean']\n",
    "# display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['defect_thresholded'], r'img\\confusion_matrix\\defect_thresholded\\resumidas\\cm_080_defect_thresholded_15.pdf', [x_label, y_label])\n",
    "\n",
    "cm = confusion_matrices[train_ratio[2]][thresh_good[2]]['defect_thresholded']['mean']\n",
    "# display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['defect_thresholded'], r'img\\confusion_matrix\\defect_thresholded\\resumidas\\cm_085_defect_thresholded_15.pdf', [x_label, y_label])\n",
    "\n",
    "cm = confusion_matrices[train_ratio[3]][thresh_good[2]]['defect_thresholded']['mean']\n",
    "# display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['defect_thresholded'], r'img\\confusion_matrix\\defect_thresholded\\resumidas\\cm_090_defect_thresholded_15.pdf', [x_label, y_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def export_classification_report_latex_style(classification_metrics_results):\n",
    "#     df = pd.DataFrame(classification_metrics_results).transpose()\n",
    "#     df.loc[:, 'precision':'f1-score'] = df.loc[:, 'precision':'f1-score'].round(2)\n",
    "#     df['support'] = df['support'].astype(int)\n",
    "\n",
    "#     print(df)\n",
    "\n",
    "#     # print(df.to_latex(index=False))\n",
    "#     print(df.style.to_latex())\n",
    "#     # display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_classification_report_latex_style(classification_metrics_results[train_ratio[1]][thresh_good[1]]['n_grains'][1])\n",
    "# classification_metrics_results[train_ratio[0]][thresh_good[1]]['n_grains']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classification_metrics_results[train_ratio[0]][thresh_good[2]]['defect_thresholded']['mean']).transpose())\n",
    "display(pd.DataFrame(classification_metrics_results[train_ratio[1]][thresh_good[2]]['defect_thresholded']['mean']).transpose())\n",
    "display(pd.DataFrame(classification_metrics_results[train_ratio[2]][thresh_good[2]]['defect_thresholded']['mean']).transpose())\n",
    "display(pd.DataFrame(classification_metrics_results[train_ratio[3]][thresh_good[2]]['defect_thresholded']['mean']).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classification_metrics_results[train_ratio[0]][thresh_good[2]]['defect_thresholded']['mean']).transpose())\n",
    "display(pd.DataFrame(classification_metrics_results[train_ratio[1]][thresh_good[2]]['defect_thresholded']['mean']).transpose())\n",
    "display(pd.DataFrame(classification_metrics_results[train_ratio[2]][thresh_good[2]]['defect_thresholded']['mean']).transpose())\n",
    "display(pd.DataFrame(classification_metrics_results[train_ratio[3]][thresh_good[2]]['defect_thresholded']['mean']).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train_model.loc[:, 'qtde_graos':'mean'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming df is the DataFrame you created earlier\n",
    "# x = np.arange(len(df))\n",
    "# y1 = df['ratio_80a255_por_1a80']\n",
    "# y2 = df['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(x, y1, label='ratio_80a255_por_1a80')\n",
    "# plt.plot(x, y2, label='ratio_80a255_por_1a80_normalizado')\n",
    "\n",
    "# plt.xlabel('npixels_1a255')\n",
    "# plt.ylabel('Values')\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming df is the DataFrame you created earlier\n",
    "# x = np.arange(len(df))\n",
    "# y1 = df['ratio_80a255_por_1a80']\n",
    "# y2 = df['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# # Set the style and context for a more elegant plot\n",
    "# sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(x, y1, label='ratio_80a255_por_1a80', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "# plt.plot(x, y2, label='ratio_80a255_por_1a80_normalizado', marker='s', linestyle='--', linewidth=2, markersize=4)\n",
    "\n",
    "# plt.xlabel('Occurrence', fontsize=14)\n",
    "# plt.ylabel('Values', fontsize=14)\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado', fontsize=16)\n",
    "# plt.legend(fontsize=12)\n",
    "\n",
    "# sns.despine()  # Remove the top and right spines for a cleaner look\n",
    "# plt.show()\n",
    "\n",
    "# print(f'Quantidade de imagens: {len(x)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"results/df_train.pkl\", \"rb\") as f:\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "with open(\"results/df_test.pkl\", \"rb\") as f:\n",
    "    df_test = pickle.load(f)\n",
    "\n",
    "with open(\"results/classification_metrics_results.pickle\", \"rb\") as f:\n",
    "    classification_metrics_results = pickle.load(f)\n",
    "\n",
    "with open(\"results/confusion_matrices.pickle\", \"rb\") as f:\n",
    "    confusion_matrices = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_metrics_results[0.90][0.15]['defect_stratified']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.loc[(df_train['percentual_defeitos'] == 0.00) & (df_train['qtde_graos'] == 100), ['npixels_1a255_por_grao', 'ratio_80a255_por_1a80', 'ratio_80a255_por_1a80_normalizado']].copy()\n",
    "display(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is the DataFrame you created earlier\n",
    "x = np.arange(len(df))\n",
    "y1 = df['ratio_80a255_por_1a80']\n",
    "y2 = df['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# Set the style and context for a more elegant plot\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(x, y1, label='Relação entre pixels claros/escuros', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "plt.plot(x, y2, label='Relação entre pixels claros/escuros normalizada', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "\n",
    "plt.xlabel('Ocorrência', fontsize=18)\n",
    "plt.ylabel('Relação', fontsize=18)\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado', fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "# Set the plot borders to black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('sem_normalizacao.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_train.copy()\n",
    "df1, df_test = normalize_dataset(df1, df_test, 'ratio_80a255_por_1a80', 1.000)\n",
    "df1 = df1.loc[(df1['percentual_defeitos'] == 0.00) & (df1['qtde_graos'] == 100), ['npixels_1a255_por_grao', 'ratio_80a255_por_1a80', 'ratio_80a255_por_1a80_normalizado']].copy()\n",
    "display(len(df1))\n",
    "\n",
    "\n",
    "# Assuming df is the DataFrame you created earlier\n",
    "x = np.arange(len(df1))\n",
    "y3 = df1['ratio_80a255_por_1a80']\n",
    "y4 = df1['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# Set the style and context for a more elegant plot\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(x, y3, label='Relação entre pixels claros/escuros', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "plt.plot(x, y4, label='Relação entre pixels claros/escuros normalizada', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "\n",
    "plt.xlabel('Ocorrência', fontsize=18)\n",
    "plt.ylabel('Relação', fontsize=18)\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado', fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Set the plot borders to black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('normalizacao_1.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_train.copy()\n",
    "df2, df_test = normalize_dataset(df2, df_test, 'ratio_80a255_por_1a80', 0.750)\n",
    "df2 = df2.loc[(df2['percentual_defeitos'] == 0.00) & (df2['qtde_graos'] == 100), ['npixels_1a255_por_grao', 'ratio_80a255_por_1a80', 'ratio_80a255_por_1a80_normalizado']].copy()\n",
    "display(len(df2))\n",
    "\n",
    "\n",
    "# Assuming df is the DataFrame you created earlier\n",
    "x = np.arange(len(df2))\n",
    "y5 = df2['ratio_80a255_por_1a80']\n",
    "y6 = df2['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# Set the style and context for a more elegant plot\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(x, y5, label='Relação entre pixels claros/escuros', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "plt.plot(x, y6, label='Relação entre pixels claros/escuros normalizada', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "\n",
    "plt.xlabel('Ocorrência', fontsize=18)\n",
    "plt.ylabel('Relação', fontsize=18)\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado', fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Set the plot borders to black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('normalizacao_075.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_train.copy()\n",
    "df3, df_test = normalize_dataset(df3, df_test, 'ratio_80a255_por_1a80', 0.500)\n",
    "df3 = df3.loc[(df3['percentual_defeitos'] == 0.00) & (df3['qtde_graos'] == 100), ['npixels_1a255_por_grao', 'ratio_80a255_por_1a80', 'ratio_80a255_por_1a80_normalizado']].copy()\n",
    "# display(len(df2))\n",
    "\n",
    "\n",
    "# Assuming df is the DataFrame you created earlier\n",
    "x = np.arange(len(df3))\n",
    "y7 = df3['ratio_80a255_por_1a80']\n",
    "y8 = df3['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# Set the style and context for a more elegant plot\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(x, y7, label='Relação entre pixels claros/escuros', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "plt.plot(x, y8, label='Relação entre pixels claros/escuros normalizada', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "\n",
    "plt.xlabel('Ocorrência', fontsize=18)\n",
    "plt.ylabel('Relação', fontsize=18)\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado', fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Set the plot borders to black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('normalizacao_050.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is the DataFrame you created earlier\n",
    "x = np.arange(len(df))\n",
    "y1 = df['ratio_80a255_por_1a80']\n",
    "y2 = df['ratio_80a255_por_1a80_normalizado']\n",
    "\n",
    "# Set the style and context for a more elegant plot\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(x, y1, label='Relação entre pixels claros/escuros', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "plt.plot(x, y2, label='Relação entre pixels claros/escuros normalizada', marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "\n",
    "plt.xlabel('Ocorrência', fontsize=14)\n",
    "plt.ylabel('Relação', fontsize=14)\n",
    "# plt.title('Comparison of ratio_80a255_por_1a80 and ratio_80a255_por_1a80_normalizado', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Set the plot borders to black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('sem_normalizacao.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_model.to_excel('model.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(classification_metrics_results[train_ratio[3]][thresh_good[1]]['n_grains']['mean']).transpose().to_excel('n_grais_mean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_true = [0, 1, 2, 2, 0]\n",
    "# y_pred = [0, 0, 2, 1, 0]\n",
    "# target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "# report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "# df = pd.DataFrame(report).transpose()\n",
    "# df = df.reset_index().rename(columns={'index': 'class'})\n",
    "# df = df[['class', 'precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "# display(df)\n",
    "# # print(df.to_latex(index=False))\n",
    "# # print(df.style.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # correlation between column 1 and column2\n",
    "# print(df_test['erro_graos'].corr(df_test['erro_defeitos']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# confusion_matrices\n",
    "\n",
    "# with open(\"results/classification_metrics_results.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(classification_metrics_results, f)\n",
    "\n",
    "\n",
    "# with open(\"results/confusion_matrices.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(confusion_matrices, f)\n",
    "\n",
    "\n",
    "\n",
    "# df_test.to_pickle('results/df_test.pkl')\n",
    "# df_train.to_pickle('results/df_train.pkl')\n",
    "# df_train_model.to_pickle('results/df_train_model.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# confusion_matrices\n",
    "\n",
    "# with open(\"results/classification_metrics_results.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(classification_metrics_results, f)\n",
    "\n",
    "\n",
    "# with open(\"results/confusion_matrices.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(confusion_matrices, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"results/classification_metrics_results.pickle\", \"rb\") as f:\n",
    "#     classification_metrics_results = pickle.load(f)\n",
    "\n",
    "# with open(\"results/confusion_matrices.pickle\", \"rb\") as f:\n",
    "#     confusion_matrices = pickle.load(f)\n",
    "\n",
    "# # display(confusion_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_metrics_results[0.75][thresh_good[1]]['n_grains'][1]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio     = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "# x = []\n",
    "# accuracy = []\n",
    "\n",
    "# for ratio in train_ratio:\n",
    "#     for i in iterations:\n",
    "#         accuracy.append(classification_metrics_results[ratio][thresh_good[1]]['n_grains'][1]['accuracy'])\n",
    "#         x.append(int(ratio*100.0))\n",
    "\n",
    "# print(np.mean(accuracy))\n",
    "# print(x)\n",
    "# print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "# accuracy = []\n",
    "# x = []\n",
    "\n",
    "# for ratio in train_ratio:\n",
    "#     for i in iterations:\n",
    "#         accuracy.append(classification_metrics_results[ratio][thresh_good[1]]['n_grains'][i]['accuracy'])\n",
    "#         x.append(int(ratio*100))\n",
    "\n",
    "# plt.boxplot(accuracy)\n",
    "# plt.xlabel('Train Ratio')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy Boxplot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "# for ratio in train_ratio:\n",
    "#     accuracy = []\n",
    "#     for i in iterations:\n",
    "#         accuracy.append(classification_metrics_results[ratio][thresh_good[1]]['n_grains'][i]['accuracy'])\n",
    "    \n",
    "#     plt.boxplot(accuracy)\n",
    "#     plt.xlabel('Train Ratio')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.title(f'Accuracy Boxplot for Ratio {int(ratio*100)}')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_ratio = [0.75, 0.8, 0.85, 0.9]\n",
    "# iterations      = range(1, 6)\n",
    "\n",
    "# accuracy_data = []\n",
    "# x_labels = []\n",
    "\n",
    "# for ratio in train_ratio:\n",
    "#     accuracy = []\n",
    "#     for i in iterations:\n",
    "#         accuracy.append(classification_metrics_results[ratio][thresh_good[2]]['n_grains'][i]['accuracy'])\n",
    "    \n",
    "#     accuracy_data.append(accuracy)\n",
    "#     # x_labels.append(int(ratio*100))\n",
    "#     x_labels.append(ratio)\n",
    "\n",
    "# plt.boxplot(accuracy_data, labels=x_labels)\n",
    "# plt.xlabel('Percentual de treino')\n",
    "# plt.ylabel('Acurácia')\n",
    "# # plt.title('Accuracy Boxplot')\n",
    "# plt.savefig('accuracy_boxplot_ngrains.pdf', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_ratio = [0.75, 0.8, 0.85, 0.9]\n",
    "iterations = range(1, 6)\n",
    "\n",
    "accuracy_data = []\n",
    "x_labels = []\n",
    "\n",
    "for ratio in train_ratio:\n",
    "    accuracy = []\n",
    "    for i in iterations:\n",
    "        accuracy.append(classification_metrics_results[ratio][thresh_good[1]]['defect_stratified'][i]['accuracy'])\n",
    "\n",
    "    accuracy_data.append(accuracy)\n",
    "    x_labels.append(ratio)\n",
    "\n",
    "# Set up the plot with the desired style\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.style.use('default')\n",
    "\n",
    "# Create the boxplot\n",
    "plt.boxplot(accuracy_data, labels=x_labels)\n",
    "\n",
    "# Set the x and y axis labels\n",
    "plt.xlabel('Percentual de treino', fontsize=16)\n",
    "plt.ylabel('Acurácia', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "# Set the plot borders to black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "# Remove gridlines\n",
    "plt.grid(False)\n",
    "\n",
    "# Save and display the plot\n",
    "# plt.savefig('accuracy_boxplot_defect_stratified.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "# accuracy_data = []\n",
    "# x_labels = []\n",
    "\n",
    "# for ratio in train_ratio:\n",
    "#     accuracy = []\n",
    "#     for i in iterations:\n",
    "#         accuracy.append(classification_metrics_results[ratio][thresh_good[1]]['n_grains'][i]['accuracy'])\n",
    "    \n",
    "#     accuracy_data.append(accuracy)\n",
    "#     x_labels.append(int(ratio*100))\n",
    "\n",
    "# plt.boxplot(accuracy_data, labels=x_labels)\n",
    "# plt.xlabel('Train Ratio')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy Boxplot')\n",
    "\n",
    "# # Set the y-axis range to show more values\n",
    "# plt.ylim(0.7, 0.9)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import pandas as pd\n",
    "\n",
    "# with open(\"results/df_train.pkl\", \"rb\") as f:\n",
    "#     df_train = pickle.load(f)\n",
    "\n",
    "# with open(\"results/df_test.pkl\", \"rb\") as f:\n",
    "#     df_test = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# df_train.to_csv(\"results/df_train.csv\", index=False)\n",
    "# df_test.to_csv(\"results/df_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrices[train_ratio[0]][thresh_good[1]]['n_grains']['mean']\n",
    "display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_075_ngrains.png', [x_label, y_label])\n",
    "\n",
    "cm = confusion_matrices[train_ratio[1]][thresh_good[1]]['n_grains']['mean']\n",
    "# display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_080_ngrains.png', [x_label, y_label])\n",
    "\n",
    "cm = confusion_matrices[train_ratio[2]][thresh_good[1]]['n_grains']['mean']\n",
    "# display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_085_ngrains.png', [x_label, y_label])\n",
    "\n",
    "cm = confusion_matrices[train_ratio[3]][thresh_good[1]]['n_grains']['mean']\n",
    "# display(cm)\n",
    "export_confusion_matrix_as_image(cm, classification_types['n_grains'], 'cm_090_ngrains.png', [x_label, y_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = ['2017/18', '2018/19', '2019/20', '2020/21', '2021/22', '2022/23']\n",
    "production = [80709.5, 100042.7, 102586.4, 87096.8, 114691.3, 125498.9]\n",
    "importation = [900.7, 1596.4, 1453.4, 3090.7, 1900, 1500]\n",
    "consumption = [59162, 64957.8, 68662.5, 72263.8, 77123.1, 81750]\n",
    "exportation = [23742.2, 41074, 34892.9, 20815.7, 37500, 44500]\n",
    "\n",
    "plt.plot(years, production, label='Produção')\n",
    "plt.plot(years, importation, label='Importação')\n",
    "plt.plot(years, consumption, label='Consumo')\n",
    "plt.plot(years, exportation, label='Exportação')\n",
    "\n",
    "plt.xlabel('Ano')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Estatísticas')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = ['2017/18', '2018/19', '2019/20', '2020/21', '2021/22', '2022/23']\n",
    "production = [80709.5, 100042.7, 102586.4, 87096.8, 114691.3, 125498.9]\n",
    "importation = [900.7, 1596.4, 1453.4, 3090.7, 1900, 1500]\n",
    "consumption = [59162, 64957.8, 68662.5, 72263.8, 77123.1, 81750]\n",
    "exportation = [23742.2, 41074, 34892.9, 20815.7, 37500, 44500]\n",
    "\n",
    "plt.bar(years, production, label='Produção')\n",
    "plt.bar(years, importation, label='Importação')\n",
    "plt.bar(years, consumption, label='Consumo')\n",
    "plt.bar(years, exportation, label='Exportação')\n",
    "\n",
    "plt.xlabel('Ano')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Estatísticas')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = ['2017/18', '2018/19', '2019/20', '2020/21', '2021/22', '2022/23 (abr/23)', '2022/23 (mai/23)']\n",
    "production = [80709.5, 100042.7, 102586.4, 87096.8, 124879.7, 124879.7, 125535.9]\n",
    "importation = [900.7, 1596.4, 1453.4, 3090.7, 2615.1, 1900, 1900]\n",
    "consumption = [59162, 64957.8, 68662.5, 72263.8, 74534.6, 79317, 79343.4]\n",
    "exportation = [23742.2, 41074, 34892.9, 20815.7, 46630.3, 48000, 48000]\n",
    "\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(years))\n",
    "\n",
    "plt.bar(index, production, width=bar_width, label='Produção')\n",
    "plt.bar(index + bar_width, importation, width=bar_width, label='Importação')\n",
    "plt.bar(index + 2*bar_width, consumption, width=bar_width, label='Consumo')\n",
    "plt.bar(index + 3*bar_width, exportation, width=bar_width, label='Exportação')\n",
    "\n",
    "plt.xlabel('Safra', fontsize=14)\n",
    "plt.ylabel('mil toneladas', fontsize=14)\n",
    "\n",
    "plt.xticks(index + 1.5*bar_width, years, rotation=45, ha='right', fontsize=12)  # Increase spacing between x-axis labels\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.tight_layout()  # Adjust the layout to prevent label overlapping\n",
    "plt.savefig('dados_producao_milho.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 312.5\n",
    "# milho = 125535.9/1000\n",
    "\n",
    "# milho/total *100\n",
    "\n",
    "\n",
    "# milho\n",
    "\n",
    "46630.3/124879.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "years = ['2017/18', '2018/19', '2019/20', '2020/21', '2021/22', '2022/23']\n",
    "categories = ['Produção', 'Importação', 'Consumo', 'Exportação']\n",
    "\n",
    "data = np.array([\n",
    "    [80709.5, 100042.7, 102586.4, 87096.8, 114691.3, 125498.9],\n",
    "    [900.7, 1596.4, 1453.4, 3090.7, 1900, 1500],\n",
    "    [59162, 64957.8, 68662.5, 72263.8, 77123.1, 81750],\n",
    "    [23742.2, 41074, 34892.9, 20815.7, 37500, 44500]\n",
    "])\n",
    "\n",
    "width = 0.15  # Width of each bar\n",
    "x = np.arange(len(years))  # X coordinate for each year\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    ax.bar(x + (i - 1.5) * width, data[i], width=width, label=categories[i])\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(years)\n",
    "ax.set_xlabel('Ano')\n",
    "ax.set_ylabel('Valor')\n",
    "ax.set_title('Estatísticas')\n",
    "ax.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the grayscale image\n",
    "image = cv2.imread('img/dataset/pre_processada/gray/a1_60_1.jpg', 0)\n",
    "\n",
    "# Calculate the histogram\n",
    "histogram = cv2.calcHist([image], [0], None, [256], [10, 256])\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure()\n",
    "plt.hist(image.ravel(), bins=256, range=[10, 256], color='gray')\n",
    "plt.xlabel('Intensidade de Pixel', fontsize=14)\n",
    "plt.ylabel('Frequência', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig('histograma_exemplo.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8067347c3ab30bb8892547d646c700eb911e2c3a99595b0254859100a92c716a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
