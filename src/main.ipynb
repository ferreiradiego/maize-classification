{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Import the packages and functions\n",
    "from tools.functions import *\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions, parameters and directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definitions, parameters and directory paths\n",
    "# Define the base path for your images\n",
    "base_path       = '../img'\n",
    "\n",
    "# Define the path to your dataset within the base path and using gray images\n",
    "dataset_path    = f'{base_path}/dataset/gray/'\n",
    "\n",
    "# List of ratios to be used for splitting the dataset into training and testing sets\n",
    "train_ratio     = [0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "# Threshold for normalizing the image data\n",
    "thresh_normalization = 0.500\n",
    "\n",
    "# List of thresholds to be considered 'good' in evaluation\n",
    "thresh_good     = [0.00, 0.10, 0.15]\n",
    "\n",
    "# Range of iterations to be performed during model training\n",
    "iterations      = range(1, 6)\n",
    "\n",
    "# Define different classification types for the model to learn. Each type is associated with a list of categories.\n",
    "classification_types = {'n_grains': ['50', '60', '70', '80', '90', '100'], \n",
    "                        'defect_stratified': ['0%', '10%', '15%', '20%', '25%', '30%'], \n",
    "                        'defect_thresholded': ['With defects', 'Healthy']}\n",
    "\n",
    "# Define labels for the x and y axes in plotting\n",
    "x_label = 'Predicted'\n",
    "y_label = 'True'\n",
    "\n",
    "## ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all image filenames in the directory specified in dataset_path\n",
    "image_filenames = read_all_images_filenames(dataset_path)\n",
    "\n",
    "# Initialize an empty DataFrame for storing training data\n",
    "df_train                    = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame for storing testing data\n",
    "df_test                     = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame for storing model's training data\n",
    "df_train_model              = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame for storing classification results\n",
    "classification_results_df   = pd.DataFrame()\n",
    "\n",
    "# Initialize a nested dictionary for storing classification metrics results. \n",
    "# The structure is organized first by training ratio, then by threshold, and finally by classification type\n",
    "classification_metrics_results = {\n",
    "    ratio: {\n",
    "        thresh: {\n",
    "            classification_type: {} for classification_type in classification_types\n",
    "        } for thresh in thresh_good\n",
    "    } for ratio in train_ratio\n",
    "}\n",
    "\n",
    "# Initialize a nested dictionary for storing confusion matrices. \n",
    "# The structure is similar to that of classification_metrics_results\n",
    "confusion_matrices = {\n",
    "    ratio: {\n",
    "        thresh: {\n",
    "            classification_type: {} for classification_type in classification_types\n",
    "        } for thresh in thresh_good\n",
    "    } for ratio in train_ratio\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates the model and performs the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the procedure for all specified training/testing percentages, thresholds to consider good grains, and the number of iterations for each set\n",
    "for ratio in train_ratio:           \n",
    "    for thresh in thresh_good:\n",
    "        for iteration in iterations:\n",
    "\n",
    "            df_train                    = pd.DataFrame()\n",
    "            df_test                     = pd.DataFrame()\n",
    "            df_train_model              = pd.DataFrame()\n",
    "\n",
    "            # Divide the dataset into train and test sets with the specified ratio\n",
    "            train_filenames, test_filenames = divide_dataset(image_filenames, ratio)\n",
    "\n",
    "            # Create dataframes for the train and test sets using the filenames and images in the specified directory\n",
    "            df_train = create_dataframes(train_filenames, dataset_path)\n",
    "            df_test = create_dataframes(test_filenames, dataset_path)\n",
    "\n",
    "            # Normalize the 'ratio_80to255_to_1to80' feature in the train and test datasets. The normalization threshold is specified\n",
    "            df_train, df_test = normalize_dataset(df_train, df_test, 'ratio_80to255_to_1to80', thresh_normalization)\n",
    "\n",
    "            # Summarize the train dataframe by grouping it by grain_quantity and defect_percentage and calculating summary statistics to generate the model\n",
    "            df_train_model = summarize_train_data(df_train)\n",
    "\n",
    "            # Call the function to calculate the average number of pixels per grain for the training dataset\n",
    "            avg_pixels_1a255_per_grain = calculate_avg_pixels_per_grain(df_train)\n",
    "\n",
    "            # Calculate number of grains\n",
    "            df_test['calculated_grain_quantity'] = df_test['npixels_1to255'].apply(calculate_number_of_grains, grain_avg = avg_pixels_1a255_per_grain)\n",
    "\n",
    "            # Estimate number of grains (in discrete values predefined)\n",
    "            df_test['estimated_grain_quantity'] = df_test['calculated_grain_quantity'].apply(estimate_number_of_grains)\n",
    "\n",
    "            # Calculate the error between the actual and estimated values for the quantity of grains\n",
    "            df_test['error_grain'] = df_test['estimated_grain_quantity'] - df_test['grain_quantity']\n",
    "\n",
    "            # Estimate the percentage of defects in the test dataset based on the number of grains and ratio\n",
    "            df_test['estimated_defect_percentage'] = df_test.apply(lambda row: estimate_defect_percentage(row['grain_quantity'], \n",
    "                                                                                                           row['normalized_ratio_80to255_to_1to80'], df_train_model), axis=1)\n",
    "\n",
    "            # Calculate the error in the estimated defect percentage\n",
    "            df_test['error_defects'] = df_test['estimated_defect_percentage'] - df_test['defect_percentage']\n",
    "\n",
    "            # Select only the columns of interest to create a summarized dataframe with the classification results\n",
    "            classification_results_df = df_test[['grain_quantity', 'defect_percentage', 'estimated_grain_quantity', 'estimated_defect_percentage', 'error_grain']].copy()\n",
    "\n",
    "            # Check the quality (healthy or defective) according to the parameterized threshold\n",
    "            classification_results_df['quality'] = (classification_results_df['defect_percentage'].apply(check_quality, thresh)).astype(int)\n",
    "            classification_results_df['estimated_quality'] = (classification_results_df['estimated_defect_percentage'].apply(check_quality, thresh)).astype(int)\n",
    "            \n",
    "            # Iterate over each classification type and get the classification results\n",
    "            for classification_type in classification_types:\n",
    "\n",
    "                cm, cr = generate_confusion_matrix_and_classification_metrics(classification_results_df, classification_types[classification_type], classification_type)\n",
    "                \n",
    "                # Update the confusion matrix and classification metrics dictionaries\n",
    "                confusion_matrices[ratio][thresh][classification_type].update({iteration: cm})\n",
    "                classification_metrics_results[ratio][thresh][classification_type].update({iteration: cr})\n",
    "\n",
    "# Apply a cross-validation by taking the average of the results obtained in each iteration\n",
    "classification_metrics_results, confusion_matrices = cross_validation(train_ratio, thresh_good, classification_types, \n",
    "                                                                      iterations, classification_metrics_results, confusion_matrices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_all_confusion_matrices_images(train_ratio, thresh_good, classification_types, iterations, confusion_matrices, base_path, [x_label, y_label])\n",
    "\n",
    "with open(\"../resources/classification_metrics_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(classification_metrics_results, f)\n",
    "\n",
    "with open(\"../resources/confusion_matrices.pickle\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)\n",
    "\n",
    "df_test.to_pickle('../resources/df_test.pkl')\n",
    "df_train.to_pickle('../resources/df_train.pkl')\n",
    "df_train_model.to_pickle('../resources/df_train_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8067347c3ab30bb8892547d646c700eb911e2c3a99595b0254859100a92c716a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
