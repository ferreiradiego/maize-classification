{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.functions import *\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions, parameters and directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = ['com_defeitos', 'sem_defeitos']\n",
    "sample = ['Amostra1', 'Amostra2', 'Amostra3', 'Amostra4', 'Amostra5']\n",
    "sub_sample = ['50', '60', '70', '80', '90', '100']\n",
    "\n",
    "# X and Y limits to crop the images\n",
    "x_start = 50\n",
    "x_end = 1100\n",
    "y_start = 250\n",
    "y_end = 1300\n",
    "\n",
    "# Directory paths of original images\n",
    "# [origin, destination]\n",
    "original_paths = ['img/dataset/original/', 'img/dataset/original/todas/']\n",
    "\n",
    "# Directory paths of pre processed images\n",
    "path_original_images    = original_paths[1]\n",
    "hsv_path                = r'img/dataset/pre_processada/hsv/'\n",
    "rgb_path                = r'img/dataset/pre_processada/rgb/'\n",
    "gray_path               = r'img/dataset/pre_processada/gray/'\n",
    "hist_path               = r'img/dataset/pre_processada/hist/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Initial preparation of the dataset, label the images according to the number of defects and the quantity of grains in the sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all possible combinations of sample and sub_sample\n",
    "for i, s in enumerate(sample):\n",
    "    for ss in sub_sample:\n",
    "        \n",
    "        # Loop over both quality items\n",
    "        for q, q_num in zip(quality, [1, 6]):\n",
    "            \n",
    "            # Define the path to the directory containing the images for the current combination of quality, sample, and sub_sample\n",
    "            path = os.path.join(original_paths[0], q, s, ss)\n",
    "            \n",
    "            # Get a list of all filenames in the directory that ends with '.jpg'\n",
    "            image_filenames = [filename for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
    "            \n",
    "            # Loop over all image filenames in the current directory\n",
    "            for j, filename in enumerate(image_filenames):\n",
    "                \n",
    "                # Define the destination filename using an f-string that incorporates the values of i, ss, and j, and also includes the corresponding quality item and a running number\n",
    "                dst = os.path.join(original_paths[1], f'a{i+q_num}_{ss}_{j+1}.jpg')\n",
    "                \n",
    "                # Copy the current file from the source directory to the destination directory\n",
    "                shutil.copy(os.path.join(path, filename), dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Perform the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line uses the glob module to get a list of all .jpg files in the path_original_images directory\n",
    "images_filenames = glob.glob(f'{path_original_images}*.jpg')\n",
    "# This line reads each image in the 'images_filenames' list in BGR format\n",
    "images_bgr = [cv2.imread(img_path) for img_path in images_filenames]\n",
    "\n",
    "# Process each image individually\n",
    "for img_path, img_bgr in zip(images_filenames, images_bgr):\n",
    "\n",
    "    # Extracts the file name\n",
    "    img_name = os.path.basename(img_path)\n",
    "\n",
    "    ## Origin and destiny paths\n",
    "    full_destiny_path_hsv = os.path.join(hsv_path, img_name)\n",
    "    full_destiny_path_rgb = os.path.join(rgb_path, img_name)\n",
    "    full_destiny_path_gray = os.path.join(gray_path, img_name)\n",
    "    full_destiny_path_hist = os.path.join(hist_path, img_name)\n",
    "    ## ---\n",
    "\n",
    "    ## Convert image to other color spaces and remove background\n",
    "    new_bgr, new_hsv, gray = convert_images(img_bgr, True)\n",
    "    ## ---\n",
    "\n",
    "    ## Crop the image\n",
    "    new_bgr = crop_image(new_bgr, x_start, x_end, y_start, y_end)\n",
    "    ## ---\n",
    "\n",
    "    # Convert image to other color spaces\n",
    "    new_bgr, new_hsv, gray = convert_images(new_bgr, False)\n",
    "    # ---\n",
    "\n",
    "    ## Calculate histogram\n",
    "    # hist = cv2.calcHist([gray], [0], None, [256], [1, 256])\n",
    "    ## ---\n",
    "\n",
    "    ## Save all images\n",
    "    # plt.clf()\n",
    "    # plt.bar(range(256), hist.ravel(), color='gray')\n",
    "    # plt.savefig(full_destiny_path_hist)\n",
    "    cv2.imwrite(full_destiny_path_rgb, new_bgr)\n",
    "    # cv2.imwrite(full_destiny_path_hsv, new_hsv)\n",
    "    cv2.imwrite(full_destiny_path_gray, gray)\n",
    "    ## ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Prepare dataset and Perform the preprocessing (only for Amostra6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_item = 'sem_defeitos'\n",
    "sample_item = 'Amostra6'\n",
    "\n",
    "# Loop over all sub_samples\n",
    "for ss in sub_sample:\n",
    "\n",
    "    # Define the path to the directory containing the images for the current combination of quality, sample, and sub_sample\n",
    "    path = os.path.join(original_paths[0], quality_item, sample_item, ss)\n",
    "\n",
    "    # Get a list of all filenames in the directory that ends with '.jpg'\n",
    "    image_filenames = [filename for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
    "\n",
    "    # Loop over all image filenames in the current directory and copy them to the destination directory\n",
    "    for j, filename in enumerate(image_filenames):\n",
    "        dst = os.path.join(original_paths[1], f'a11_{ss}_{j+1}.jpg')\n",
    "        shutil.copy(os.path.join(path, filename), dst)\n",
    "\n",
    "# Read all JPG images in the directory that start with 'a11' and store them in a list\n",
    "images_filenames = glob.glob(f'{path_original_images}a11*.jpg')\n",
    "images_bgr = [cv2.imread(img_path) for img_path in images_filenames]\n",
    "\n",
    "for img_path, img_bgr in zip(images_filenames, images_bgr):\n",
    "\n",
    "    img_name = os.path.basename(img_path)\n",
    "\n",
    "    ## Origin and destiny paths\n",
    "    full_destiny_path_hsv = os.path.join(hsv_path, img_name)\n",
    "    full_destiny_path_rgb = os.path.join(rgb_path, img_name)\n",
    "    full_destiny_path_gray = os.path.join(gray_path, img_name)\n",
    "    full_destiny_path_hist = os.path.join(hist_path, img_name)\n",
    "    ## ---\n",
    "\n",
    "    ##  ---------------\n",
    "\n",
    "    ## Convert image to other color spaces\n",
    "    new_bgr, new_hsv, gray = convert_images(img_bgr, True)\n",
    "    ## ---\n",
    "\n",
    "    ## Set lower and upper bounds for thresholding\n",
    "    lower_bound = np.array([20, 20, 80])\n",
    "    upper_bound = np.array([255, 255, 255])\n",
    "\n",
    "    ## Apply thresholding to the BGR image\n",
    "    thresh = cv2.inRange(new_bgr, lower_bound, upper_bound)\n",
    "\n",
    "    ## Define kernel for erosion and apply it to the thresholded image\n",
    "    kernel = np.ones((15,15), np.uint8)\n",
    "    erosion = cv2.erode(thresh, kernel, iterations=3)\n",
    "\n",
    "    ## Define kernel for dilation and apply it to the eroded image\n",
    "    kernel = np.ones((17,17), np.uint8)\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations=5)\n",
    "\n",
    "    # Create a mask with the result of the dilation\n",
    "    mask = cv2.bitwise_not(dilation)\n",
    "\n",
    "    # Apply the mask to the BGR image\n",
    "    result = cv2.bitwise_and(new_bgr, new_bgr, mask=mask)\n",
    "    \n",
    "    ##  ---------------\n",
    "\n",
    "    ## Crop the image\n",
    "    result = crop_image(result, 20, 1200, 200, 1600)\n",
    "    ## ---\n",
    "\n",
    "    # Convert image to other color spaces\n",
    "    new_bgr, new_hsv, gray = convert_images(result, False)\n",
    "    # ---\n",
    "\n",
    "    # Calculate histogram\n",
    "    # hist = cv2.calcHist([gray], [0], None, [256], [1, 256])\n",
    "    # ---\n",
    "\n",
    "    ## Save all images\n",
    "    # plt.clf()\n",
    "    # plt.bar(range(256), hist.ravel(), color='gray')\n",
    "    # plt.savefig(full_destiny_path_hist)\n",
    "    cv2.imwrite(full_destiny_path_rgb, new_bgr)\n",
    "    # cv2.imwrite(full_destiny_path_hsv, new_hsv)\n",
    "    cv2.imwrite(full_destiny_path_gray, gray)\n",
    "    ## ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57153c8d1f1ac0000c806ae49eb46db6eb4ffa131fd2297fc564656c33f539b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
